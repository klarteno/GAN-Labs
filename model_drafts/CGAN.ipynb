{"cells":[{"cell_type":"markdown","source":["# This model is not ouputing yet clear images , it is still a working draft"],"metadata":{"id":"F_zf9a2zQwGE"}},{"cell_type":"markdown","metadata":{"id":"qBnlG9Gnbbil"},"source":["###### lowered thelearning rate for:\n","###### - generator from 0.0002 to 0.00008\n","###### - discriminator from 0.002 to  0.001\n","###### and GAN trainning is considerably faster and debug images considerably better"]},{"cell_type":"markdown","metadata":{"id":"Np-tMiEvbbir"},"source":["# Spectrally Normalized Conditional Generative Adversarial Networks (SN-CGAN)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pnk8CEd1bbis"},"outputs":[],"source":["%pip install ipympl\n","%pip install torchinfo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7YlJzkaVa67c"},"outputs":[],"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib widget\n","\n","\n","import torch\n","from torch import nn\n","import torchvision\n","from torch.utils.data import  DataLoader\n","import torch.optim as optim\n","\n","from tqdm.notebook import tqdm_notebook\n","\n","\n","import time\n","\n","import numpy as np\n","\n","from numpy.random import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPworHY5bbiv","outputId":"368a6b6c-9e79-4401-fa29-9ae2bb9057c3"},"outputs":[{"data":{"text/plain":["'\\nfrom google.colab import drive\\n\\ndrive.mount(\"/content/drive\", force_remount=True)\\n%cd \\'/content/drive/My Drive/Colab Notebooks/GANs\\'\\n'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount=True)\n","%cd '/content/drive/My Drive/Colab Notebooks/GANs'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"92muljR0bbiw","outputId":"243f2611-1419-438f-d202-3680fb91c1d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri Nov 25 12:26:05 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 526.98       Driver Version: 526.98       CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n","| N/A   39C    P0    N/A /  N/A |      0MiB /  2048MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["%load_ext tensorboard\n","\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WE_k-EUdbbix","outputId":"1fda8ebc-532e-4be7-b31f-456f7ad98393"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current working directory: c:\\Users\\androgo\\Documents\\Python Scripts\\myLabProject\\GANs_VAE\n"]}],"source":["import os\n","\n","print(\"Current working directory: {0}\".format(os.getcwd()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KGKe9O96bbix"},"outputs":[],"source":["from utils.gans.gans_building_blocks import GaussianNoise, PixelwiseNorm, MinibatchStdDev"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"toqMg7jKbbiy"},"outputs":[],"source":["image_size=128"]},{"cell_type":"markdown","metadata":{"id":"7PdM0sfMbbiz"},"source":["The Discriminator and Generator layer for the label conditioning uses an embedding layer to transform the labels into vectors of size embedding_dim ,this expansion of every label (which is anumber) into a vector of size embedding_dim is done to allow the generator to distinguish better the label and to learn with higher probability a different representation for each label.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DRci35VJbbi0"},"outputs":[],"source":["class Conditional_GANGenerator(nn.Module):\n","    \"\"\"\n","    noise_dim: the dimension of the noise vector, a scalar\n","    main : :py:class:`torch.nn.Sequential`\n","      The sequential container\n","\n","    \"\"\"\n","\n","    def __init__(self, noise_dim=100, condition_label_dim=3):\n","        \"\"\"Init function\n","\n","        Parameters\n","        ----------\n","        noise_dim : int\n","          The dimension of the noise\n","        conditional_dim : int\n","          The dimension of the conditioning variable\n","        channels : int\n","          The number of channels in the image\n","        \"\"\"\n","        super(Conditional_GANGenerator, self).__init__()\n","    \n","        embedding_dim = 100\n","        \n","        # output size : torch.Size([32, 3, 25])\n","        self.label_conditioned_generator = nn.Sequential(\n","                    nn.Embedding(condition_label_dim, embedding_dim),\n","                    nn.Linear(embedding_dim, 300),\n","                    nn.BatchNorm1d(3)\n","                    )\n","         \n","        # layer for the noise used for generation of the image (as is done in the original GAN paper and other GANs)\n","        #output size :torch.Size([32, 12800])\n","        out_features=2*image_size*5*5\n","        self.latent = nn.Sequential(\n","                    nn.Linear(noise_dim, out_features),\n","                    #nn.BatchNorm1d(5*5*256),\n","                    nn.GroupNorm(25*2, out_features),\n","                    nn.LeakyReLU(0.1, inplace=True)\n","                    \n","                    )  \n","        \n","\n","        # Build the neural network\n","        self.gen1 = nn.Sequential(\n","\n","            # input is Z, going into a convolution\n","            nn.ConvTranspose2d(\n","                in_channels=292,\n","                out_channels=292,\n","                kernel_size=5, stride=2, padding=1, bias=False\n","            ),\n","            nn.BatchNorm2d(292),\n","            nn.LeakyReLU(0.1,inplace=True),\n","            PixelwiseNorm()\n","        )\n","        \n","        self.gen2 = nn.Sequential(\n","\n","            nn.ConvTranspose2d(\n","                in_channels=292,\n","                out_channels=256,\n","                kernel_size=7, stride=1, padding=1, bias=False,\n","            ),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(0.1,inplace=True),\n","            nn.PixelShuffle(2),\n","            PixelwiseNorm()\n","        )\n","            \n","        self.gen3 = nn.Sequential(\n","\n","            nn.ConvTranspose2d(\n","                in_channels=64,\n","                out_channels=64,\n","                kernel_size=3, stride=2, padding=1, bias=False,\n","            ),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.1,inplace=True),\n","            PixelwiseNorm()\n","        )\n","        \n","        self.gen4 = nn.Sequential(\n","\n","            nn.ConvTranspose2d(\n","                in_channels=64,\n","                out_channels=32,\n","                kernel_size=5, stride=1, padding=0, bias=False,\n","            ),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(0.1,inplace=True),\n","            PixelwiseNorm()\n","\n","        )\n","\n","        self.gen5 = nn.Sequential(\n","\n","            nn.ConvTranspose2d(\n","                in_channels=32,\n","                out_channels=32,\n","                kernel_size=3, stride=2, padding=0, bias=False,\n","            ),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(0.1,inplace=True),\n","            PixelwiseNorm()\n","\n","        )\n","         \n","        self.gen6 = nn.Sequential(\n","\n","            nn.ConvTranspose2d(\n","                in_channels=32,\n","                out_channels=3,\n","                kernel_size=3, stride=1, padding=0, bias=False\n","            ),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, noise, condition_label):\n","        \"\"\"Forward function\n","\n","        Parameters\n","        ----------\n","        noise : : noise_tensor :py:class:`torch.Tensor`\n","         \n","        condition : : condition_tensor :py:class:`torch.Tensor`\n","          The conditional one hot encoded vector for the minibatch.\n","\n","        Returns\n","        -------\n","        :py:class:`torch.Tensor`\n","          the output of the generator (i.e. an image)\n","\n","        \"\"\"\n","        \n","        noise_vector = noise\n","        \n","        label_output = self.label_conditioned_generator(condition_label)\n","        label_output = label_output.view(label_output.shape[0],-1, 5, 5)  # torch.Size([32, 3, 5, 5])\n","        \n","        latent_output = self.latent(noise_vector)\n","        latent_output = latent_output.view(latent_output.shape[0],-1,5,5) # torch.Size([32, 512, 5, 5])\n","        \n","        concat_vector = torch.cat((latent_output, label_output), dim=1)   # torch.Size([32, 515, 5, 5])\n","\n","        output_gen = self.gen1(concat_vector)\n","        output_gen = self.gen2(output_gen)\n","        output_gen = self.gen3(output_gen)\n","        output_gen = self.gen4(output_gen)\n","        output_gen     = self.gen5(output_gen)\n","        output     = self.gen6(output_gen)\n","\n","        \n","        return output[:,:,:image_size,:image_size] # output 129 x 129"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6idjwEBCbbi3"},"outputs":[],"source":["class Conditional_GANDiscriminator(nn.Module):\n","    \"\"\"Class implementating the conditional GAN discriminator\n","\n","    Attributes\n","    ----------\n","    conditional_dim: int\n","      The dimension of the conditioning variable.\n","    channels: int\n","      The number of channels in the input image (default: 3).\n","    main : :py:class:`torch.nn.Sequential`\n","      The sequential container\n","\n","    \"\"\"\n","\n","    def __init__(self, condition_label_dim=3):\n","        \"\"\"Init function\n","\n","        Parameters\n","        ----------\n","        conditional_dim: int\n","          The dimension of the conditioning variable.\n","        channels: int\n","          The number of channels in the input image (default: 3).\n","        \"\"\"\n","        super(Conditional_GANDiscriminator, self).__init__()\n","\n","        embedding_dim = 50\n","\n","        self.label_condition_disc = nn.Sequential(\n","                nn.Embedding(condition_label_dim, embedding_dim),\n","                      nn.Linear(embedding_dim, 6*image_size*image_size),\n","                      nn.BatchNorm1d(3))\n","      \n","      \n","        self.disc1 = nn.Sequential(\n","\n","            # Gaussian noise with stdev 0.1 relative to input tensor\n","            # Salimans et al used it in the output layer of D while OpenAI has it on the input\n","            GaussianNoise(),\n","\n","            # input is (nc) x 128 x 128\n","            nn.utils.spectral_norm(\n","                nn.Conv2d(\n","                    in_channels=21,\n","                    out_channels=128,\n","                    kernel_size=5, stride=1, padding=0, bias=False\n","                )\n","            ),\n","            nn.LeakyReLU(inplace=True),\n","            nn.Dropout(0.2)\n","        )\n","        \n","        self.disc2 = nn.Sequential(\n","\n","            nn.utils.spectral_norm(\n","                nn.Conv2d(\n","                    in_channels=128,\n","                    out_channels=128, #256\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0,\n","                    bias=False,\n","                )\n","            ),\n","            nn.AvgPool2d(2),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(inplace=True),\n","            nn.Dropout(0.2)\n","        )\n","        \n","        self.disc3 = nn.Sequential(\n","\n","            nn.utils.spectral_norm(\n","                nn.Conv2d(\n","                    in_channels=128,   #256\n","                    out_channels=128,\n","                    kernel_size=5,\n","                    stride=1,\n","                    padding=0,\n","                    bias=False,\n","                ) \n","            ),\n","            nn.AvgPool2d(2),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(inplace=True),\n","            nn.Dropout(0.2)\n","        )\n","        \n","        \n","        self.disc4 = nn.Sequential(\n","\n","            nn.utils.spectral_norm(\n","                nn.Conv2d(\n","                    in_channels=128,\n","                    out_channels=64,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0,\n","                    bias=False,\n","                )\n","            ),\n","            nn.AvgPool2d(3),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(inplace=True),\n","            nn.Dropout(0.2)\n","        )\n","        \n","        \n","        self.disc5 = nn.Sequential(\n","            nn.utils.spectral_norm(\n","                nn.Conv2d(\n","                    in_channels=64,\n","                    out_channels=32,\n","                    kernel_size=7, stride=1, padding=1 ,bias=False\n","                )\n","            ),\n","            nn.AvgPool2d(2),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(inplace=True),\n","            nn.Dropout(0.2)\n","        )\n","        \n","        self.disc6 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=32,\n","                out_channels=1,\n","                kernel_size=3, stride=1, padding=1, bias=False\n","            ),\n","            nn.AvgPool2d(2),\n","            nn.Dropout(0.2),\n","            MinibatchStdDev()\n","\n","            # nn.Sigmoid() # replaced by  nn.BCEWithLogitsLoss()\n","        )\n","    \n","\n","    def forward(self, images, labels_condition):\n","        \"\"\"Forward function\n","\n","        Parameters\n","        ----------\n","        images: a batch of images tensors with dimension (im_dim)\n","       \n","        condition : : condition_tensor :py:class:`torch.Tensor`\n","              The corresponding conditional feature maps.\n","        Returns\n","        -------\n","        :py:class:`torch.Tensor`\n","          the output of the discriminator\n","        \"\"\"\n","\n","        label_output = self.label_condition_disc(labels_condition)\n","        label_output = label_output.view(label_output.shape[0], -1, image_size, image_size)\n","        \n","        input_discriminator = torch.cat((images, label_output), dim=1)\n","\n","\n","        disc_pred = self.disc1(input_discriminator)\n","        disc_pred = self.disc2(disc_pred)\n","        disc_pred = self.disc3(disc_pred)\n","        disc_pred = self.disc4(disc_pred)\n","        disc_pred = self.disc5(disc_pred)\n","        disc_pred = self.disc6(disc_pred)\n","\n","        return disc_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cH0YC7BYbbi4","outputId":"7fb6e089-841b-49a9-edb6-41721b01c69b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cuda:0\n","Name of current CUDA device: NVIDIA GeForce MX250\n"]}],"source":["from utils.utils_cuda import clear_cuda_cache, get_device\n","\n","from torchinfo import summary\n","\n","clear_cuda_cache()\n","DEVICE=get_device()\n","\n","from utils.utils_cuda import seed_everything\n","\n","# Hyperparameters\n","RANDOM_SEED = 42\n","seed_everything(seed=RANDOM_SEED)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sLpwyqmvbbi5"},"source":["### Test the Generator\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OPoyn2O5bbi5","outputId":"44f3d867-8a70-461b-a20e-fd063c489b3d"},"outputs":[{"name":"stdout","output_type":"stream","text":["output generator shape:  torch.Size([4, 3, 128, 128])\n","GENERATOR ARCHITECTURE: \n"]},{"data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","Conditional_GANGenerator                 [4, 3, 128, 128]          --\n","├─Sequential: 1-1                        [4, 3, 300]               --\n","│    └─Embedding: 2-1                    [4, 3, 100]               300\n","│    └─Linear: 2-2                       [4, 3, 300]               30,300\n","│    └─BatchNorm1d: 2-3                  [4, 3, 300]               6\n","├─Sequential: 1-2                        [4, 6400]                 --\n","│    └─Linear: 2-4                       [4, 6400]                 646,400\n","│    └─GroupNorm: 2-5                    [4, 6400]                 12,800\n","│    └─LeakyReLU: 2-6                    [4, 6400]                 --\n","├─Sequential: 1-3                        [4, 292, 11, 11]          --\n","│    └─ConvTranspose2d: 2-7              [4, 292, 11, 11]          2,131,600\n","│    └─BatchNorm2d: 2-8                  [4, 292, 11, 11]          584\n","│    └─LeakyReLU: 2-9                    [4, 292, 11, 11]          --\n","│    └─PixelwiseNorm: 2-10               [4, 292, 11, 11]          --\n","├─Sequential: 1-4                        [4, 64, 30, 30]           --\n","│    └─ConvTranspose2d: 2-11             [4, 256, 15, 15]          3,662,848\n","│    └─BatchNorm2d: 2-12                 [4, 256, 15, 15]          512\n","│    └─LeakyReLU: 2-13                   [4, 256, 15, 15]          --\n","│    └─PixelShuffle: 2-14                [4, 64, 30, 30]           --\n","│    └─PixelwiseNorm: 2-15               [4, 64, 30, 30]           --\n","├─Sequential: 1-5                        [4, 64, 59, 59]           --\n","│    └─ConvTranspose2d: 2-16             [4, 64, 59, 59]           36,864\n","│    └─BatchNorm2d: 2-17                 [4, 64, 59, 59]           128\n","│    └─LeakyReLU: 2-18                   [4, 64, 59, 59]           --\n","│    └─PixelwiseNorm: 2-19               [4, 64, 59, 59]           --\n","├─Sequential: 1-6                        [4, 32, 63, 63]           --\n","│    └─ConvTranspose2d: 2-20             [4, 32, 63, 63]           51,200\n","│    └─BatchNorm2d: 2-21                 [4, 32, 63, 63]           64\n","│    └─LeakyReLU: 2-22                   [4, 32, 63, 63]           --\n","│    └─PixelwiseNorm: 2-23               [4, 32, 63, 63]           --\n","├─Sequential: 1-7                        [4, 32, 127, 127]         --\n","│    └─ConvTranspose2d: 2-24             [4, 32, 127, 127]         9,216\n","│    └─BatchNorm2d: 2-25                 [4, 32, 127, 127]         64\n","│    └─LeakyReLU: 2-26                   [4, 32, 127, 127]         --\n","│    └─PixelwiseNorm: 2-27               [4, 32, 127, 127]         --\n","├─Sequential: 1-8                        [4, 3, 129, 129]          --\n","│    └─ConvTranspose2d: 2-28             [4, 3, 129, 129]          864\n","│    └─Tanh: 2-29                        [4, 3, 129, 129]          --\n","==========================================================================================\n","Total params: 6,583,750\n","Trainable params: 6,583,750\n","Non-trainable params: 0\n","Total mult-adds (G): 6.31\n","==========================================================================================\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 63.44\n","Params size (MB): 26.34\n","Estimated Total Size (MB): 89.78\n","=========================================================================================="]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["batch_size=4\n","\n","input_noise = torch.rand(batch_size, 100, dtype=torch.float32, device=DEVICE)\n","cond_labels = torch.zeros(batch_size, 3, dtype=torch.long, device=DEVICE)\n","\n","\n","generator = Conditional_GANGenerator(noise_dim=100, condition_label_dim=3).to(DEVICE).eval()\n","\n","output = generator.forward(input_noise, cond_labels)\n","print('output generator shape: ',output.shape)\n","\n","print('GENERATOR ARCHITECTURE: ')\n","#summary(generator, input_size=((batch_size, 100),(batch_size, 3)), device=DEVICE)\n","summary(generator, input_data=(input_noise, cond_labels), device=DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"oUfr4SfDbbi6"},"source":["### Test the Discriminator\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MNCsxMGMduMc","outputId":"16df3e58-4140-400e-d242-fd72a67672b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["output discriminator shape:  torch.Size([8, 1, 1, 1])\n","DISCRIMINATOR ARCHITECTURE: \n"]},{"data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","Conditional_GANDiscriminator             [8, 1, 1, 1]              --\n","├─Sequential: 1-1                        [8, 3, 98304]             --\n","│    └─Embedding: 2-1                    [8, 3, 50]                250\n","│    └─Linear: 2-2                       [8, 3, 98304]             5,013,504\n","│    └─BatchNorm1d: 2-3                  [8, 3, 98304]             6\n","├─Sequential: 1-2                        [8, 128, 124, 124]        --\n","│    └─GaussianNoise: 2-4                [8, 21, 128, 128]         --\n","│    └─Conv2d: 2-5                       [8, 128, 124, 124]        67,200\n","│    └─LeakyReLU: 2-6                    [8, 128, 124, 124]        --\n","│    └─Dropout: 2-7                      [8, 128, 124, 124]        --\n","├─Sequential: 1-3                        [8, 128, 61, 61]          --\n","│    └─Conv2d: 2-8                       [8, 128, 122, 122]        147,456\n","│    └─AvgPool2d: 2-9                    [8, 128, 61, 61]          --\n","│    └─BatchNorm2d: 2-10                 [8, 128, 61, 61]          256\n","│    └─LeakyReLU: 2-11                   [8, 128, 61, 61]          --\n","│    └─Dropout: 2-12                     [8, 128, 61, 61]          --\n","├─Sequential: 1-4                        [8, 128, 28, 28]          --\n","│    └─Conv2d: 2-13                      [8, 128, 57, 57]          409,600\n","│    └─AvgPool2d: 2-14                   [8, 128, 28, 28]          --\n","│    └─BatchNorm2d: 2-15                 [8, 128, 28, 28]          256\n","│    └─LeakyReLU: 2-16                   [8, 128, 28, 28]          --\n","│    └─Dropout: 2-17                     [8, 128, 28, 28]          --\n","├─Sequential: 1-5                        [8, 64, 8, 8]             --\n","│    └─Conv2d: 2-18                      [8, 64, 26, 26]           73,728\n","│    └─AvgPool2d: 2-19                   [8, 64, 8, 8]             --\n","│    └─BatchNorm2d: 2-20                 [8, 64, 8, 8]             128\n","│    └─LeakyReLU: 2-21                   [8, 64, 8, 8]             --\n","│    └─Dropout: 2-22                     [8, 64, 8, 8]             --\n","├─Sequential: 1-6                        [8, 32, 2, 2]             --\n","│    └─Conv2d: 2-23                      [8, 32, 4, 4]             100,352\n","│    └─AvgPool2d: 2-24                   [8, 32, 2, 2]             --\n","│    └─BatchNorm2d: 2-25                 [8, 32, 2, 2]             64\n","│    └─LeakyReLU: 2-26                   [8, 32, 2, 2]             --\n","│    └─Dropout: 2-27                     [8, 32, 2, 2]             --\n","├─Sequential: 1-7                        [8, 1, 1, 1]              --\n","│    └─Conv2d: 2-28                      [8, 1, 2, 2]              288\n","│    └─AvgPool2d: 2-29                   [8, 1, 1, 1]              --\n","│    └─Dropout: 2-30                     [8, 1, 1, 1]              --\n","│    └─MinibatchStdDev: 2-31             [8, 1, 1, 1]              --\n","==========================================================================================\n","Total params: 5,813,088\n","Trainable params: 5,813,088\n","Non-trainable params: 0\n","Total mult-adds (M): 742.80\n","==========================================================================================\n","Input size (MB): 1.57\n","Forward/backward pass size (MB): 352.24\n","Params size (MB): 23.25\n","Estimated Total Size (MB): 377.07\n","=========================================================================================="]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["batch_size=8\n","\n","# Instantiate Discriminator\n","discriminator = Conditional_GANDiscriminator(condition_label_dim=5).to(DEVICE).eval()\n","\n","input_img_discrim = torch.rand(batch_size, 3, 128, 128, dtype=torch.float32,device=DEVICE)\n","cond_labels = torch.zeros(batch_size, 3,  dtype=torch.long,device=DEVICE)\n","\n","output = discriminator.forward(input_img_discrim, cond_labels)\n","print('output discriminator shape: ', output.shape)\n","\n","\n","print('DISCRIMINATOR ARCHITECTURE: ')\n","batch_size=32\n","#summary(discriminator, input_size=((batch_size, 3, 128, 128),(batch_size, 13, 128, 128)), device=DEVICE)\n","summary(discriminator,input_data=(input_img_discrim, cond_labels), device=DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZ7IpnuHbbi7"},"outputs":[],"source":["from utils.gans.gans_statistics_utils import GANStatisticsSaver\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from utils.gans.gans_folders import FolderStructure\n","\n","from pathlib import Path"]},{"cell_type":"markdown","metadata":{"id":"VTtC2kzxbbi7"},"source":["### Trainning\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZoo6gg6gIKy"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import time\n","\n","import logging\n","\n","logger = logging.getLogger(\"CGAN_Trainer\")\n","\n","\n","class ConditionalGAN_Trainer(object):\n","    \"\"\"Class to train a Conditional GAN\n","\n","    Attributes\n","    ----------\n","    generator : :py:class:`torch.nn.Module`\n","      The generator network\n","    discriminator : :py:class:`torch.nn.Module`\n","      The discriminator network\n","    image_size: list of :obj:`int`\n","      The size of the images in this format: [channels,height, width]\n","    batch_size: int\n","      The size of your minibatch\n","    noise_dim: int\n","      The dimension of the noise (input to the generator)\n","    conditional_dim: int\n","      The dimension of the conditioning variable\n","    use_gpu: bool\n","      If you would like to use the gpu\n","    fixed_noise : :py:class:`torch.Tensor`\n","      The fixed input noise to the generator.\n","    fixed_one_hot_label : :py:class:`torch.Tensor`\n","      The set of fixed one-hot encoded conditioning variable\n","    criterion : :py:class:`torch.nn.BCELoss`\n","      The binary cross-entropy loss\n","\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        net_cond_GANGenerator: Conditional_GANGenerator,\n","        net_cond_GANDiscriminator: Conditional_GANDiscriminator,\n","        noise_dim=100,\n","        conditional_dim=3,\n","        folder_structure: FolderStructure = FolderStructure(trainning_output = Path('trainings_output') / Path('SNCGAN_training_output'))\n","\n","    ):\n","        \"\"\"Init function\n","\n","        Parameters\n","        ----------\n","        net_cond_GANGenerator : :py:class:`torch.nn.Module`\n","          The generator network\n","        net_cond_GANDiscriminator : :py:class:`torch.nn.Module`\n","          The discriminator network\n","        image_size: list of :obj:`int`\n","          The size of the images in this format: [channels,height, width]\n","        batch_size: int\n","          The size of your minibatch\n","        noise_dim: int\n","          The dimension of the noise (input to the generator)\n","        conditional_dim: int\n","          The dimension of the conditioning variable\n","        use_gpu: bool\n","          If you would like to use the gpu\n","        verbosity_level: int\n","          The level of verbosity output to stdout\n","\n","        \"\"\"\n","        self.net_cond_GANGenerator = net_cond_GANGenerator\n","        self.net_cond_GANDiscriminator = net_cond_GANDiscriminator\n","        # binary cross-entropy loss:This loss combines a Sigmoid layer and the BCELoss in one single class.\n","        self.criterion = nn.BCEWithLogitsLoss()\n","        \n","        # move stuff to GPU if needed\n","        self.net_cond_GANGenerator.to(DEVICE)\n","        self.net_cond_GANDiscriminator.to(DEVICE)\n","        self.criterion.to(DEVICE)\n","        \n","        self.noise_dim = noise_dim\n","        self.conditional_dim = conditional_dim\n","\n","        self.folder_structure = folder_structure\n","        \n","        # instantiate tensorboard\n","        # (tensorboard) writer will output to ./runs/ directory by default\n","        self.writer = SummaryWriter(log_dir=self.folder_structure.tensorboard_folder)\n","        #%reload_ext tensorboard\n","        # %tensorboard --logdir Cond_SNGAN_training_output/Tensorboard_runs\n","        \n","        # fixed conditional noise - used to generate samples (one for each value of the conditional variable)\n","        ''''\n","        self.fixed_noise = torch.FloatTensor(\n","            self.conditional_dim, noise_dim, 1, 1\n","        ).normal_(0, 1)\n","        self.fixed_one_hot_label = torch.FloatTensor(\n","            self.conditional_dim, self.conditional_dim, 1, 1\n","        ).zero_()\n","        for k in range(self.conditional_dim):\n","            self.fixed_one_hot_label[k, k] = 1\n","        '''\n","\n","\n","    # smoothing labels class=1 to [0.94, 0.98]\n","    def smooth_positive_labels(self, real_labels):\n","        real_labels = real_labels.to('cpu')\n","        labels = real_labels - 0.08 + (random(real_labels.shape) * 0.02)\n","\n","        return labels.to(DEVICE)\n","    \n","    def get_noise(self, batch_size):\n","        noise = torch.randn(batch_size, self.noise_dim, dtype=torch.float32, device=DEVICE)\n","        \n","        #create tensor with random values in range (min, max)\n","        ''' \n","        max = 1\n","        min = -1\n","        \n","        rand_tensor = (max-min)*noise + min\n","        '''\n","\n","        return noise\n","    def get_noise2(self, batch_size):\n","        noise = torch.tensor((), dtype=torch.float32, device=DEVICE).new_empty((batch_size, self.noise_dim)).uniform_(-1,1)        \n","        return noise\n","\n","    def get_conditional_labels(self, batch_size):\n","          self.fixed_one_hot_label = torch.zeros(batch_size, self.conditional_dim,  dtype=torch.long, device=DEVICE)\n","\n","          self.fixed_one_hot_label_list = []\n","          \n","          for label in range(self.fixed_one_hot_label.shape[1]):\n","              _tensor=self.fixed_one_hot_label.clone()\n","              _tensor[:,label] = 1\n","              self.fixed_one_hot_label_list.append(_tensor)\n","              \n","          #labels unset , so the generator will generate simple random images\n","          self.fixed_one_hot_label_list.append(self.fixed_one_hot_label)\n","          \n","          return self.fixed_one_hot_label_list    \n","\n","    def record_evaluations(self, ganStatisticsSaver, \n","                           gener_loss, discr_loss,\n","                           d_real_loss, d_fake_loss, \n","                           train_loader, epoch, batch_idx):\n","         \n","        _gener_loss = np.round(gener_loss.item(), 2)\n","        _discr_loss = np.round(discr_loss.item(), 2)\n","        # write losses for G and D to tensorboard\n","        self.writer.add_scalars('Cond_GAN_LOSS', {'GEN': np.round(gener_loss.item(), 2), \n","                                                  'DISC': np.round(discr_loss.item(), 2)},\n","                                len(train_loader) * epoch + batch_idx + 1)\n","\n","        ganStatisticsSaver.save_train_generator_loss_per_batch(_gener_loss)\n","        ganStatisticsSaver.save_train_discriminator_loss_per_batch(_discr_loss)\n","\n","        # write losses for G and D to tensorboard\n","        self.writer.add_scalars('DISC_LOSS', {'DISC_REAL': np.round(d_real_loss.item(), 2),\n","                                                'DISC_FAKE': np.round(d_fake_loss.item(), 2)},\n","                                len(train_loader) * epoch + batch_idx + 1)\n","\n","    def save_images(self,model:nn.Module, fixed_one_hot_label_list,labels, ganStatisticsSaver,train_loader,epoch,batch_idx,is_debug=False):\n","        model.eval()\n","        log_list_generated_images = []\n","        # generate the debug imagery on current generator model for every \n","        with torch.no_grad():\n","          for cond_label in fixed_one_hot_label_list:\n","              log_generated_images = model(self.get_noise(self.batch_size),\n","                                                  cond_label)            \n","              log_list_generated_images.append(log_generated_images.detach().cpu())\n","          \n","          log_generated_images = model(self.get_noise(self.batch_size),\n","                                                  labels)     \n","        \n","        log_list_generated_images.append(log_generated_images.detach().cpu())\n","        \n","        log_list_generated_images = torch.cat(log_list_generated_images, dim=0) \n","        # make grid of 5x5 generated images to get an idea of G's performance\n","        list_intermediate_imagery_grid = torchvision.utils.make_grid(\n","            log_list_generated_images, nrow=self.batch_size, padding=2, normalize = True)\n","        \n","        model.train()\n","\n","        \n","        #add epoch images\n","        if not is_debug:\n","          id = str(epoch)\n","          ganStatisticsSaver.save_images_normalized_to_folder(\n","                      log_list_generated_images, \n","                      self.folder_structure.trainning_images_generated,\n","                      id)\n","          \n","          self.writer.add_image('intermediate generated imagery',\n","                                list_intermediate_imagery_grid, len(train_loader) * epoch  + 1)\n","        #add debug images\n","        else:\n","          id = str(epoch) + '_' + str(batch_idx)\n","          ganStatisticsSaver.save_images_normalized_to_folder(\n","                      log_list_generated_images, \n","                      self.folder_structure.debug_images_generated,\n","                      id)\n","      \n","    def train(\n","        self, \n","        train_loader:DataLoader, \n","        ganStatisticsSaver: GANStatisticsSaver,\n","        optimizer_discriminator:optim.Optimizer,\n","        optimizer_generator:optim.Optimizer,\n","        epochs_range=(0, 15)\n","    ):\n","        \"\"\"trains the Conditional GAN.\n","\n","        Parameters\n","        ----------\n","        train_loader: :py:class:`torch.utils.data.train_loader`\n","          The train_loader for your data\n","        epochs_range: tuple of `int`\n","          The first element is the starting epoch and the second element is the ending epoch (exclusive) for training the model (e.g. (0, 10) will train the model for 10 epochs,(10, 15) will train the model for 5 epochs more than the previous training)\n","     \n","        \"\"\"\n","        \n","        image, _ = next(iter(train_loader))\n","        batch_size = image.shape[0]\n","        self.batch_size=batch_size\n","        fixed_one_hot_label_list = self.get_conditional_labels(batch_size)\n","\n","\n","        with torch.no_grad():\n","          self.net_cond_GANGenerator.eval()\n","          self.net_cond_GANDiscriminator.eval()\n","          \n","          self.writer.add_graph(self.net_cond_GANGenerator, \n","                                (self.get_noise(batch_size),\n","                                fixed_one_hot_label_list[2]))\n","          \n","          image = image.to(DEVICE)\n","          self.writer.add_graph(self.net_cond_GANDiscriminator, \n","                                (image, fixed_one_hot_label_list[2]))\n","\n","        self.net_cond_GANGenerator.train()\n","        self.net_cond_GANDiscriminator.train()\n","\n","\n","        #the dataloader is modified to have batches of fixed size , so is safe to use these outside the loop\n","        # smooth the real label = 1\n","        real_labels = self.smooth_positive_labels(torch.ones(batch_size, device=DEVICE))\n","        fake_labels = torch.zeros(batch_size,1,1,1, device=DEVICE)  \n","\n","\n","        start_training_time = time.time()\n","\n","        for epoch in range(epochs_range[0], epochs_range[1]):\n","            clear_cuda_cache()\n","\n","            ganStatisticsSaver.discriminator_loss_real[epoch] = []\n","            ganStatisticsSaver.discriminator_loss_fake[epoch] = []\n","            ganStatisticsSaver.generator_loss_fake[epoch] = []\n","                      \n","            #for batch_idx, (features, labels) in enumerate(tqdm.tqdm(train_loader), 0):\n","            for batch_idx, (features, labels) in enumerate(tqdm_notebook(iterable=train_loader, desc='epoch '+str(epoch), total=len(train_loader)), 0):\n","\n","                # real images\n","                real_images = features.to(DEVICE, non_blocking=True)\n","                \n","                labels = labels.pin_memory() \n","                labels = labels.to(DEVICE, non_blocking=True).long()\n","                labels = labels.squeeze()\n","                     \n","                self.net_cond_GANDiscriminator.zero_grad()\n","    \n","                discr_pred_real = self.net_cond_GANDiscriminator(real_images, labels)\n","                \n","                real_labels=real_labels.view_as(discr_pred_real)\n","                d_real_loss = self.criterion(discr_pred_real, real_labels)\n","\n","\n","                # =========\n","                # GENERATOR\n","                # =========\n","                # generated (fake) images\n","                noise = self.get_noise(batch_size)\n","                \n","                gen_images = self.net_cond_GANGenerator(noise, labels)\n","                discr_pred_fake = self.net_cond_GANDiscriminator(gen_images.detach(), labels)\n","                d_fake_loss = self.criterion(discr_pred_fake,  fake_labels)\n","     \n","                # train with fake\n","                #D_fake_loss.backward()\n","              \n","                discr_loss = d_real_loss + d_fake_loss\n","                # track discrimantor failure : if the discriminator loss is NAN or zero then the discriminator is not learning \n","                assert not torch.isnan(discr_loss).any()\n","                assert  discr_loss.all()\n","                \n","                discr_loss.backward()\n","                optimizer_discriminator.step()\n","        \n","\n","                # =============\n","                # DISCRIMINATOR\n","                # =============\n","        \n","                # Train generator with real labels\n","                self.net_cond_GANGenerator.zero_grad()\n","                \n","                noise = self.get_noise(batch_size)\n","                #try disable\n","                gen_images = self.net_cond_GANGenerator(noise, labels)\n","                \n","                d_out_gen = self.net_cond_GANDiscriminator(gen_images, labels) \n","                gener_loss = self.criterion(d_out_gen, real_labels)\n","                \n","                gener_loss.backward()\n","                optimizer_generator.step()\n","                           \n","                self.record_evaluations(ganStatisticsSaver, \n","                                        gener_loss, discr_loss,\n","                                        d_real_loss, d_fake_loss, \n","                                        train_loader, epoch, batch_idx)\n","              \n","                #debug images\n","                if (batch_idx % int(len(train_loader)/4) == 0):\n","                  with torch.no_grad():\n","                    self.save_images(self.net_cond_GANGenerator,fixed_one_hot_label_list,labels,\n","                                     ganStatisticsSaver,train_loader,epoch,batch_idx,\n","                                     is_debug=True)\n","              \n","              \n","            with torch.no_grad():\n","              self.save_images(self.net_cond_GANGenerator,fixed_one_hot_label_list,labels,\n","                                     ganStatisticsSaver,train_loader,epoch,batch_idx,\n","                                     is_debug=False)\n","              \n","              \n","            # save a checkpoint of the DCGAN every epoch\n","            # performance often degrades past a certain epoch and may not recover\n","            # save generator\n","            torch.save({\n","                'model_state_dict': self.net_cond_GANGenerator.state_dict(),\n","                'optimizer_state_dict': optimizer_generator.state_dict(),\n","                'epoch': epoch,\n","                'loss': gener_loss.item(),\n","            }, self.folder_structure.get_path_checkpoints_for_file( 'generator_checkpoint_epoch_' \n","                                                      + str(epoch) + '.pt')) \n","            \n","            # save discriminator\n","            torch.save({\n","                'model_state_dict': self.net_cond_GANDiscriminator.state_dict(),\n","                'optimizer_state_dict': optimizer_discriminator.state_dict(),\n","                'epoch': epoch,\n","                'loss': discr_loss.item(),\n","            }, self.folder_structure.get_path_checkpoints_for_file('discriminator_checkpoint_epoch_'\n","        \n","                                                      + str(epoch) + '.pt'))\n","        end_training_time = time.time()\n","\n","        total_training_time = end_training_time - start_training_time\n","\n","        ganStatisticsSaver.save_total_training_time(total_training_time)\n","\n","        ganStatisticsSaver.set_trainned_model(self.net_cond_GANGenerator, self.net_cond_GANDiscriminator)\n","        ganStatisticsSaver.set_trainned_optimizer(optimizer_generator, optimizer_discriminator)\n","\n","        ganStatisticsSaver.save_model_params(\n","            self.folder_structure.trainning_final_model_folder, epoch\n","        )\n","      \n","    \n","        self.writer.flush()\n","        self.writer.close()"]},{"cell_type":"markdown","metadata":{"id":"wWhzXNXKbbi9"},"source":["### Load the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ynwuK41Nbbi-","outputId":"a661ed92-b401-4a73-e139-922f9b7da50c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device: cuda:0\n","Name of current CUDA device: NVIDIA GeForce MX250\n","train loader lenghth 545\n","images shape:  torch.Size([8, 3, 128, 128])\n","labels shape:  torch.Size([8, 3, 1, 1])\n","labels: \n"]}],"source":["from utils.gans.utils_gan import weights_init\n","from utils_data.utils_data_load import get_celeba_datasets_with_labels\n","from utils.utils_cuda import clear_cuda_cache, get_device\n","DEVICE=get_device()\n","\n","\n","# during training the cuda device is working almost 100 %\n","BATCH_SIZE = 32\n","train_loader = get_celeba_datasets_with_labels(image_size=128,batch_size=BATCH_SIZE, desired_attr = ['Male', 'Brown_Hair','Eyeglasses'])\n","\n","print('train loader lenghth', len(train_loader))\n","images, labels = next(iter(train_loader))\n","print('images shape: ', images.shape)\n","print('labels shape: ', labels.shape)\n","print('labels: ' )\n","\n","torch.cuda.init()\n","clear_cuda_cache()\n"]},{"cell_type":"markdown","metadata":{"id":"cnC8OZeobbi-"},"source":["### GANs init utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxDHIxjrbbi_"},"outputs":[],"source":["def get_GANs_component_models():\n","    generator = Conditional_GANGenerator()\n","    generator.apply(weights_init)\n","    generator.to(DEVICE)\n","\n","    discriminator = Conditional_GANDiscriminator()\n","    discriminator.apply(weights_init)\n","    discriminator.to(DEVICE)\n","    \n","    return generator, discriminator\n","\n","#learning_rate_generator = 0.000001\n","#learning_rate_discriminator = 0.0009\n","def get_GANs_optimizers(generator:nn.Module, discriminator:nn.Module,\n","                    learning_rate_generator = 0.001, learning_rate_discriminator = 0.01):\n","\n","    \n","    optimizer_discriminator = optim.AdamW(\n","        discriminator.parameters(),\n","        lr=learning_rate_discriminator,\n","        betas=(0.5, 0.999)\n","    )\n","\n","    optimizer_generator = optim.AdamW(\n","        generator.parameters(),\n","        lr=learning_rate_generator,\n","        betas=(0.5, 0.999),\n","    )\n","    \n","    return optimizer_discriminator, optimizer_generator"]},{"cell_type":"markdown","metadata":{"id":"C8GPJbJ_bbi_"},"source":["### Start trainning the GANs models\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["f38fd3007ab047a1b43b0dd0c9a8496a"]},"id":"MHBG9ID0bbi_","outputId":"cd9e26fd-bcab-403b-be0b-fac6e615e72b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f38fd3007ab047a1b43b0dd0c9a8496a","version_major":2,"version_minor":0},"text/plain":["epoch 0:   0%|          | 0/545 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [18], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m# use main method for lunch if dataloader has the number of jobs set\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 30\u001b[0m     trainer\u001b[39m.\u001b[39;49mtrain(train_loader, ganStatisticsSaver,\n\u001b[0;32m     31\u001b[0m                   optimizer_discriminator, optimizer_generator, \n\u001b[0;32m     32\u001b[0m                   epochs_range\u001b[39m=\u001b[39;49m(NUM_EPOCHS_START, NUM_EPOCHS_END),\n\u001b[0;32m     33\u001b[0m                   )\n\u001b[0;32m     34\u001b[0m     trainer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39m# use next  for lunch if dataloader does not have the number of jobs set\u001b[39;00m\n","Cell \u001b[1;32mIn [15], line 312\u001b[0m, in \u001b[0;36mConditionalGAN_Trainer.train\u001b[1;34m(self, train_loader, ganStatisticsSaver, optimizer_discriminator, optimizer_generator, epochs_range)\u001b[0m\n\u001b[0;32m    309\u001b[0m gener_loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m    310\u001b[0m optimizer_generator\u001b[39m.\u001b[39mstep()\n\u001b[1;32m--> 312\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecord_evaluations(ganStatisticsSaver, \n\u001b[0;32m    313\u001b[0m                         gener_loss, discr_loss,\n\u001b[0;32m    314\u001b[0m                         d_real_loss, d_fake_loss, \n\u001b[0;32m    315\u001b[0m                         train_loader, epoch, batch_idx)\n\u001b[0;32m    317\u001b[0m \u001b[39m#debug images\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[39mif\u001b[39;00m (batch_idx \u001b[39m%\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(train_loader)\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n","Cell \u001b[1;32mIn [15], line 143\u001b[0m, in \u001b[0;36mConditionalGAN_Trainer.record_evaluations\u001b[1;34m(self, ganStatisticsSaver, gener_loss, discr_loss, d_real_loss, d_fake_loss, train_loader, epoch, batch_idx)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecord_evaluations\u001b[39m(\u001b[39mself\u001b[39m, ganStatisticsSaver, \n\u001b[0;32m    139\u001b[0m                        gener_loss, discr_loss,\n\u001b[0;32m    140\u001b[0m                        d_real_loss, d_fake_loss, \n\u001b[0;32m    141\u001b[0m                        train_loader, epoch, batch_idx):\n\u001b[1;32m--> 143\u001b[0m     _gener_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(gener_loss\u001b[39m.\u001b[39;49mitem(), \u001b[39m2\u001b[39m)\n\u001b[0;32m    144\u001b[0m     _discr_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(discr_loss\u001b[39m.\u001b[39mitem(), \u001b[39m2\u001b[39m)\n\u001b[0;32m    145\u001b[0m     \u001b[39m# write losses for G and D to tensorboard\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","generator, discriminator = get_GANs_component_models()\n","optimizer_discriminator, optimizer_generator = get_GANs_optimizers(generator, discriminator)\n","\n","\n","folder_structure = FolderStructure(trainning_output = Path('trainings_output') / Path('SNCGAN_training_output'))\n","\n","# remove prevoius training output if training is not restarted from a checkpoint \n","REMOVE_PREVIOUSE_TRAINNING_OUTPUT = True\n","\n","if REMOVE_PREVIOUSE_TRAINNING_OUTPUT:\n","    folder_structure.remove_trainning_folder_output()\n","    \n","    #create or clear folders if training is restarted or training models are not loaded\n","    folder_structure.create_folders()\n","    folder_structure.clean_folders()\n","\n","\n","\n","trainer = ConditionalGAN_Trainer(\n","    generator, discriminator, folder_structure = folder_structure\n",")\n","\n","ganStatisticsSaver = GANStatisticsSaver()\n","\n","NUM_EPOCHS_END = 30\n","NUM_EPOCHS_START = 0\n","\n","# use main method for lunch if dataloader has the number of jobs set\n","if __name__ == '__main__':\n","    trainer.train(train_loader, ganStatisticsSaver,\n","                  optimizer_discriminator, optimizer_generator, \n","                  epochs_range=(NUM_EPOCHS_START, NUM_EPOCHS_END),\n","                  )\n","    trainer = None\n","\n","\n","# use next  for lunch if dataloader does not have the number of jobs set\n","''' \n","NUM_EPOCHS = 2\n","trainer.train(train_loader, ganStatisticsSaver, n_epochs=NUM_EPOCHS)\n","'''"]},{"cell_type":"markdown","metadata":{"id":"BuLmJUC5bbjA"},"source":["### Start trainning the GANs from a loaded model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WxX40yNQbbjA","outputId":"d2287c16-7409-49b0-d8b6-91b9505e4049"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mFailed to start the Kernel. \n","\u001b[1;31mUnable to start Kernel 'Python (pytorch_env_kernel) (Python 3.9.15)' due to connection timeout. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["def train_loaded_model(train_loader, NUMBER_EPOCHS_TO_TRAIN):\n","    \n","    generator, discriminator = get_GANs_component_models()\n","    optimizer_discriminator, optimizer_generator = get_GANs_optimizers(generator,discriminator)\n","\n","    folder_structure = FolderStructure(trainning_output =Path('trainings_output') / Path('SNCGAN_training_output'))\n","\n","    ganStatisticsSaver = GANStatisticsSaver()\n","    last_epoch = ganStatisticsSaver.load_trainned_models(generator, discriminator, \n","                                            optimizer_generator, \n","                                            optimizer_discriminator,\n","                                            folder_structure.trainning_final_model_folder)       \n","    \n","    trainer = ConditionalGAN_Trainer(\n","        generator, discriminator, folder_structure = folder_structure\n","    )\n","    \n","    \n","    NUM_EPOCHS_START = last_epoch + 1\n","    NUM_EPOCHS_END = NUM_EPOCHS_START + NUMBER_EPOCHS_TO_TRAIN\n","\n","    trainer.train(train_loader, ganStatisticsSaver, \n","                optimizer_discriminator, optimizer_generator, \n","                  epochs_range=(NUM_EPOCHS_START, NUM_EPOCHS_END))\n","    \n","    \n","    return generator, folder_structure, ganStatisticsSaver, NUM_EPOCHS_END\n","    \n","#se to True if you want to train from a checkpoint \n","#START_TRAINNING_FROM_CHECKPOINT = False\n","START_TRAINNING_FROM_CHECKPOINT = True\n","\n","\n","if START_TRAINNING_FROM_CHECKPOINT:\n","    NUMBER_EPOCHS_TO_TRAIN=4\n","    generator, folder_structure, ganStatisticsSaver,NUM_EPOCHS_END = train_loaded_model(train_loader, NUMBER_EPOCHS_TO_TRAIN)\n","    "]},{"cell_type":"markdown","metadata":{"id":"6VLGbV_zbbjB"},"source":["### Use Tensorboard to vizualiza all training combines, below is displayed only for current trainning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBzk9uxQbbjB","outputId":"76be1627-ddd3-45b5-fa16-80560636b893"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mFailed to start the Kernel. \n","\u001b[1;31mUnable to start Kernel 'Python (pytorch_env_kernel) (Python 3.9.15)' due to connection timeout. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["NUM_EPOCHS = NUM_EPOCHS_END + 1\n","\n","from utils.utils_plotting import (\n","    plot_multiple_trainning_evals,\n","    plot_trainning_eval\n","\n",")\n","\n","plot_multiple_trainning_evals(\n","    evals_list=(\n","        ganStatisticsSaver.train_discriminator_loss_per_batch,\n","        ganStatisticsSaver.train_generator_loss_per_batch,\n","    ),\n","    num_epochs=NUM_EPOCHS,\n","    custom_labels_list=(\" -- Discriminator\", \" -- Generator\"),\n",")\n","\n","plot_trainning_eval(\n","    ganStatisticsSaver.train_discriminator_loss_per_batch,\n","    num_epochs=NUM_EPOCHS,\n","    type_plot=\"Loss\",\n","    custom_label=\" Discriminator\",\n",")\n","\n","plot_trainning_eval(\n","    ganStatisticsSaver.train_generator_loss_per_batch,\n","    num_epochs=NUM_EPOCHS,\n","    type_plot=\"Loss\",\n","    custom_label=\" Generator\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XMWhtNoPbbjC","outputId":"98ec9cd2-64de-4ba0-a0f6-ff8738f46bd9"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mFailed to start the Kernel. \n","\u001b[1;31mUnable to start Kernel 'Python (pytorch_env_kernel) (Python 3.9.15)' due to connection timeout. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["from utils_data.utils_folders import write_to_disk_images_stacked\n","\n","resulting_images = write_to_disk_images_stacked(folder_source_imgs=folder_structure.trainning_images_generated,\n","                             folder_output_batches_stacked=folder_structure.stacks_images_generated,\n","                             folder_output_all_stacked=folder_structure.one_stack_images_generated,\n","                             num_epochs=NUM_EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jhY0pha1bbjC","outputId":"50c52283-6b69-47ab-bd5d-e67b8ca97afc"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mFailed to start the Kernel. \n","\u001b[1;31mUnable to start Kernel 'Python (pytorch_env_kernel) (Python 3.9.15)' due to connection timeout. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["from utils.utils_images import display_images\n","\n","# plot images saved in folder in a stack of images \n","%matplotlib inline\n","\n","display_images(resulting_images)"]},{"cell_type":"markdown","metadata":{"id":"VX7NkvzrbbjD"},"source":["### Interpolate images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzQwgVi8bbjD","outputId":"2e94924d-6d3f-4b6d-cf72-31a0ee825ce6"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mFailed to start the Kernel. \n","\u001b[1;31mUnable to start Kernel 'Python (pytorch_env_kernel) (Python 3.9.15)' due to connection timeout. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["#DEVICE='cpu'\n","DEVICE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a52F5rhFbbjD","outputId":"df470464-4a42-4d5d-9558-bd6a8a7b5c8b"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mFailed to start the Kernel. \n","\u001b[1;31mUnable to start Kernel 'Python (pytorch_env_kernel) (Python 3.9.15)' due to connection timeout. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["from utils.gans.interpolate_images import interpolate_images\n","\n","generator.eval() # set generator to evaluation mode \n","interpolate_images(folder_root = folder_structure.trainning_model_interpolated_images,\n","                      DEVICE=DEVICE, generator=generator)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"vscode":{"interpreter":{"hash":"201b6068cbed112f118c29a6393440d4ce4dc02105f31305c61d838eb972bb93"}},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}